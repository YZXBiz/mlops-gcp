{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Training Operationalization\n",
        "\n",
        "Training operationalization is the process of building and testing a repeatable ML training pipeline and then deploying it to a target execution environment.\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## CI/CD Pipeline for Training\n",
        "\n",
        "```{mermaid}\n",
        "flowchart TD\n",
        "    A[Source Code Repository] --> B[CI Pipeline]\n",
        "    B --> C[Unit Testing]\n",
        "    B --> D[Integration Testing]\n",
        "    B --> E[Build Training Pipeline]\n",
        "\n",
        "    C --> F{Tests Pass?}\n",
        "    D --> F\n",
        "    E --> F\n",
        "\n",
        "    F -->|No| G[Feedback to Developer]\n",
        "    F -->|Yes| H[Store Artifacts]\n",
        "\n",
        "    H --> I[CD Pipeline]\n",
        "    I --> J[Deploy to Test Environment]\n",
        "    J --> K[End-to-End Testing]\n",
        "    K --> L{Pipeline Valid?}\n",
        "\n",
        "    L -->|No| M[Rollback]\n",
        "    L -->|Yes| N[Deploy to Staging]\n",
        "    N --> O[Smoke Testing]\n",
        "    O --> P{Ready for Production?}\n",
        "\n",
        "    P -->|No| M\n",
        "    P -->|Yes| Q[Deploy to Production]\n",
        "    Q --> R[Monitor Pipeline Health]\n",
        "\n",
        "    style A fill:#e3f2fd\n",
        "    style B fill:#fff3e0\n",
        "    style I fill:#fff3e0\n",
        "    style Q fill:#c8e6c9\n",
        "    style F fill:#ffecb3\n",
        "    style L fill:#ffecb3\n",
        "    style P fill:#ffecb3\n",
        "```\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "::::{admonition} Deployment Configurations\n",
        ":class: tip\n",
        "For MLOps, ML engineers should be able to use configurations to deploy the ML pipelines. The configurations specify variables like:\n",
        "\n",
        "- The target deployment environment (development, test, staging, etc.)\n",
        "- The data sources to access during execution in each environment\n",
        "- The service account to use for running compute workloads\n",
        "- Compute resources and scaling parameters\n",
        "- Security and access policies\n",
        "::::\n",
        "\n",
        "A pipeline typically goes through a series of testing and staging environments before it is released to production. The number of testing and staging environments varies depending on standards established in the organization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Environment Configuration Management\n",
        "import os\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Any\n",
        "\n",
        "@dataclass\n",
        "class EnvironmentConfig:\n",
        "    \"\"\"Configuration for different deployment environments\"\"\"\n",
        "    environment: str\n",
        "    data_source: str\n",
        "    model_registry_url: str\n",
        "    compute_resources: Dict[str, Any]\n",
        "    monitoring_enabled: bool\n",
        "\n",
        "def get_environment_config(env_name: str) -> EnvironmentConfig:\n",
        "    \"\"\"Get configuration for specific environment\"\"\"\n",
        "    \n",
        "    configs = {\n",
        "        \"development\": EnvironmentConfig(\n",
        "            environment=\"development\",\n",
        "            data_source=\"dev_dataset\",\n",
        "            model_registry_url=\"dev-registry.internal\",\n",
        "            compute_resources={\"cpu\": \"2\", \"memory\": \"4Gi\"},\n",
        "            monitoring_enabled=False\n",
        "        ),\n",
        "        \"staging\": EnvironmentConfig(\n",
        "            environment=\"staging\",\n",
        "            data_source=\"staging_dataset\",\n",
        "            model_registry_url=\"staging-registry.internal\",\n",
        "            compute_resources={\"cpu\": \"4\", \"memory\": \"8Gi\"},\n",
        "            monitoring_enabled=True\n",
        "        ),\n",
        "        \"production\": EnvironmentConfig(\n",
        "            environment=\"production\",\n",
        "            data_source=\"prod_dataset\",\n",
        "            model_registry_url=\"prod-registry.internal\",\n",
        "            compute_resources={\"cpu\": \"8\", \"memory\": \"16Gi\"},\n",
        "            monitoring_enabled=True\n",
        "        )\n",
        "    }\n",
        "    \n",
        "    return configs.get(env_name, configs[\"development\"])\n",
        "\n",
        "# Example usage\n",
        "current_env = os.getenv(\"DEPLOYMENT_ENV\", \"development\")\n",
        "config = get_environment_config(current_env)\n",
        "print(f\"Environment: {config.environment}\")\n",
        "print(f\"Data Source: {config.data_source}\")\n",
        "print(f\"Compute Resources: {config.compute_resources}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Continuous Integration (CI) Deep Dive\n",
        "\n",
        "### CI Testing Strategies\n",
        "\n",
        "::::{admonition} Comprehensive CI Testing\n",
        ":class: important\n",
        "The CI process should include multiple types of tests:\n",
        "\n",
        "**Unit Testing:**\n",
        "- Test feature engineering logic and data transformation functions\n",
        "- Test individual model components and methods (e.g., categorical encoding functions)\n",
        "- Validate mathematical operations and statistical computations\n",
        "\n",
        "**Integration Testing:**\n",
        "- Test integration between pipeline components\n",
        "- Verify data flow between pipeline steps\n",
        "- Test component interfaces and contracts\n",
        "\n",
        "**Model Testing:**\n",
        "- Test that model training converges (loss decreases over iterations)\n",
        "- Test model training doesn't produce NaN values\n",
        "- Test model can overfit on a few sample records (sanity check)\n",
        "- Validate that each component produces expected artifacts\n",
        "::::\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Unit Test for Feature Engineering\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def test_feature_scaling():\n",
        "    \"\"\"Unit test for feature scaling functionality\"\"\"\n",
        "    # Sample data\n",
        "    data = pd.DataFrame({\n",
        "        'feature1': [1, 2, 3, 4, 5],\n",
        "        'feature2': [10, 20, 30, 40, 50]\n",
        "    })\n",
        "    \n",
        "    # Apply scaling\n",
        "    scaler = StandardScaler()\n",
        "    scaled_data = scaler.fit_transform(data)\n",
        "    \n",
        "    # Test assertions\n",
        "    assert np.allclose(scaled_data.mean(axis=0), 0, atol=1e-7), \"Mean should be close to 0\"\n",
        "    assert np.allclose(scaled_data.std(axis=0), 1, atol=1e-7), \"Std should be close to 1\"\n",
        "    \n",
        "    print(\"✅ Feature scaling test passed!\")\n",
        "    return True\n",
        "\n",
        "# Run the test\n",
        "test_feature_scaling()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### CI Workflow Details\n",
        "\n",
        "```{mermaid}\n",
        "flowchart LR\n",
        "    A[Code Commit] --> B[Trigger CI]\n",
        "    B --> C[Code Checkout]\n",
        "    C --> D[Environment Setup]\n",
        "    D --> E[Dependency Installation]\n",
        "    \n",
        "    E --> F[Unit Tests]\n",
        "    E --> G[Integration Tests]\n",
        "    E --> H[Model Tests]\n",
        "    E --> I[Code Quality Checks]\n",
        "    \n",
        "    F --> J[Collect Results]\n",
        "    G --> J\n",
        "    H --> J\n",
        "    I --> J\n",
        "    \n",
        "    J --> K{All Tests Pass?}\n",
        "    K -->|No| L[Notify Developer]\n",
        "    K -->|Yes| M[Build Artifacts]\n",
        "    \n",
        "    M --> N[Store in Registry]\n",
        "    N --> O[Trigger CD]\n",
        "    \n",
        "    style A fill:#e1f5fe\n",
        "    style B fill:#fff3e0\n",
        "    style M fill:#fff8e1\n",
        "    style O fill:#c8e6c9\n",
        "    style K fill:#ffecb3\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Integration Test for Pipeline Components\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def test_training_pipeline_integration():\n",
        "    \"\"\"Integration test for the complete training pipeline\"\"\"\n",
        "    \n",
        "    # Generate sample data\n",
        "    X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, random_state=42)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    \n",
        "    # Training step\n",
        "    model = RandomForestClassifier(n_estimators=10, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # Validation step\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    \n",
        "    # Integration test assertions\n",
        "    assert accuracy > 0.7, f\"Model accuracy {accuracy:.3f} is below threshold 0.7\"\n",
        "    assert not np.any(np.isnan(y_pred)), \"Predictions contain NaN values\"\n",
        "    assert len(y_pred) == len(y_test), \"Prediction length mismatch\"\n",
        "    \n",
        "    print(f\"✅ Integration test passed! Accuracy: {accuracy:.3f}\")\n",
        "    return True\n",
        "\n",
        "# Run the integration test\n",
        "test_training_pipeline_integration()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "::::{warning} Common CI Test Failures\n",
        "Watch out for these common issues:\n",
        "- **Dependency conflicts:** Version mismatches between development and CI environments\n",
        "- **Data schema changes:** Tests failing due to unexpected data format changes\n",
        "- **Resource limitations:** Tests failing due to insufficient compute or memory in CI environment\n",
        "- **Flaky tests:** Non-deterministic failures due to random seeds or timing issues\n",
        "::::\n",
        "\n",
        "## Summary\n",
        "\n",
        "::::{admonition} Best Practices for Training Operationalization\n",
        ":class: tip\n",
        "- **Infrastructure as Code:** Use tools like Terraform to provision ML platform environments\n",
        "- **Configuration Management:** Externalize all environment-specific configurations\n",
        "- **Automated Testing:** Implement comprehensive testing at multiple levels\n",
        "- **Progressive Deployment:** Use staging environments to validate before production\n",
        "- **Monitoring and Logging:** Implement observability from day one\n",
        "- **Documentation:** Maintain clear documentation for all pipeline components and processes\n",
        "- **Security:** Implement security scanning and compliance checks in CI/CD\n",
        "- **Resource Optimization:** Monitor and optimize compute resource usage\n",
        "::::\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
